from ultralytics import YOLO

if __name__ == '__main__':
    # Load a pretrained YOLO11n model
    model = YOLO("/yolo_workspace/针织/训练/train5_yolo11l/weights/best.pt")
    # Run inference on 'bus.jpg' with arguments
    results = model.predict(
        # source="/media/autumn/新加卷/现场识别错误数据_1",  # 指定推理的数据源。可以是图像路径、视频文件、目录、URL 或用于实时馈送的设备 ID。
        source="/media/autumn/新加卷/测试数据集",  # 指定推理的数据源。可以是图像路径、视频文件、目录、URL 或用于实时馈送的设备 ID。
        conf=0.2,  # 设置检测的最小置信度阈值。如果检测到的对象置信度低于此阈值，则将不予考虑。调整该值有助于减少误报。
        iou=0.5,  # 非最大抑制 (NMS) 的交叉重叠 (IoU) 阈值。较低的数值可以消除重叠的方框，从而减少检测次数，这对减少重复检测非常有用。
        imgsz=1024,  # 定义用于推理的图像大小。可以是一个整数（如 320）或一个（高度、宽度）元组。适当调整大小可以提高检测效率、精确度和处理速度。
        half=False,  # 是否启用半精度（FP16）推理，可加快支持的 GPU 上的模型推理速度，同时将对精度的影响降至最低。
        device=0,  # 指定用于推理的设备（例如：`cpu`, `cuda:0` 或 `0`）。允许用户选择 CPU、特定 GPU 或其他计算设备执行模型。
        batch=1,  # 指定推理的批量大小（仅当来源为目录、视频文件或 .txt 文件）。更大的批次规模可以提供更高的吞吐量，缩短推理所需的总时间。
        max_det=300,  # 每幅图像允许的最大检测次数。限制模型在单次推理中可以检测到的物体总数，防止在密集场景中产生过多的输出。
        vid_stride=1,  # 视频输入的帧间距。允许跳过视频中的帧，以加快处理速度，但会牺牲时间分辨率。数值为 1 时会处理每一帧，数值越大越跳帧。
        stream_buffer=False,
        # 是否对接收到的视频流帧进行排队。如果为 False，旧帧会被丢弃，以容纳新帧（针对实时应用进行了优化）。如果为 True，则在缓冲区中排队等待新帧，确保不会跳过任

        # 何帧，但如果推理的 FPS 低于流的 FPS，则会导致延迟。
        visualize=False,  # 是否在推理过程中激活模型特征的可视化，从而深入了解模型 "看到 "了什么。这对调试和模型解释非常有用。
        augment=False,  # 是否对预测进行测试时间增强（TTA），从而在牺牲推理速度的情况下提高检测的鲁棒性。
        agnostic_nms=True,  # 是否启用与类别无关的非最大抑制 (NMS)，可合并不同类别的重叠方框。这在多类检测场景中非常有用，因为在这种场景中，类的重叠很常见。
        classes=None,  # 根据一组类别 ID 过滤预测结果。只有属于指定类别的检测结果才会返回。这对于在多类检测任务中集中检测相关对象非常有用。
        retina_masks=False,  # 是否返回高分辨率分割掩码。返回的掩码 (masks.data) 如果启用，将与原始图像大小相匹配。如果禁用，它们将与推理过程中使用的图像大小一致。
        embed=None,  # 指定从中提取特征向量或嵌入的层。这对聚类或相似性搜索等下游任务非常有用。
        project="针织/测试",  # 保存预测结果的项目目录名称，如果 `save` 已启用。
        name=None,  # 预测运行的名称。用于在项目文件夹内创建一个子目录，在 `save` 已启用时存储预测输出结果。

        # 可视化参数
        show=False,  # 如果为 True，在一个窗口中显示注释的图像或视频。有助于在开发或测试过程中提供即时视觉反馈。
        save=True,  # 是否将注释的图像或视频保存到文件中。这对记录、进一步分析或共享结果非常有用。使用 CLI 时默认为 True，在 Python 中使用时默认为 False。
        save_frames=True,  # 处理视频时，是否将单个帧保存为图像。可用于提取特定帧或进行详细的逐帧分析。
        save_txt=True,
        # 是否将检测结果保存在文本文件中，格式为 `[class] [x_center] [y_center] [width] [height] [confidence]`。有助于与其他分析工具集成。
        save_conf=True,  # 是否在保存的文本文件中包含置信度分数。增强了后期处理和分析的细节。
        save_crop=False,  # 是否保存经过裁剪的检测图像。可用于数据集扩充、分析或创建特定物体的重点数据集。
        show_labels=True,  # 是否在可视输出中显示每次检测的标签。让用户立即了解检测到的物体。
        show_conf=True,  # 是否在标签旁显示每次检测的置信度得分。让人了解模型对每次检测的确定性。
        show_boxes=True,  # 是否在检测到的物体周围绘制边框。对于图像或视频帧中物体的视觉识别和定位至关重要。
        line_width=3,  # 指定边界框的线宽。如果为 None，根据图像大小自动调整线宽。提供可视化定制，使图像更加清晰。
    )
